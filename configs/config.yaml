# configs/config.yaml

ioda_base_url: "https://api.ioda.inetintel.cc.gatech.edu/v2"
news_api_key: "YOUR_NEWSAPI_KEY"
openai_api_key: ""
gemini_api_key: ""
use_llm: true
openai_model: "phi3:mini"
default_location: "Sanaa, Yemen"
default_window_hours: 4
llm_provider: "ollama" # options: none|openai|ollama|llama_cpp
llm_base_url: "http://localhost:11434/v1"      # OpenAI-compatible Ollama endpoint
local_model_path: ""   # path to GGUF when using llama_cpp
temperature: 0.2
max_tokens: 120
